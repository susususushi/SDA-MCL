learner         :       HSML
optim           :       AdamW
learning_rate   :       0.0005
momentum        :       0
weight_decay    :       0.0001
dataset         :       cifar100
n_classes       :       100
n_tasks         :       10
mem_size        :       1000
mem_batch_size  :       64
batch_size      :       10
nf              :       64
tf_type         :       full
training_type   :       inc
seed            :       0
randaug_m       :       15
randaug_n       :       3
randaug2_weight :       0.5
rotation_weight :       0.1
layer1_weight   :       0.25
layer1_rotation_weight :   0.25